{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2026dfc8-763d-486a-a098-54cffed60919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Databricks: Author and deploy an MCP tool-calling LangGraph agent\n",
    "\n",
    "This notebook shows how to author a LangGraph agent that connects to MCP servers hosted on Databricks. LangGraph's graph-based architecture gives you complete control over agent behavior, making it the right choice when you need custom workflows or multi-step reasoning patterns.\n",
    "\n",
    "Connect your agent to data and tools through MCP servers. Databricks provides managed MCP servers for Unity Catalog functions, vector search, and Genie spaces. You can also connect to custom MCP servers that you host as Databricks Apps. See [MCP on Databricks](https://docs.databricks.com/aws/en/generative-ai/mcp/).\n",
    "\n",
    "In this notebook, you:\n",
    "\n",
    "- Author a LangGraph agent\n",
    "- Connect the agent to MCP servers to access Databricks-hosted tools\n",
    "- Test the agent and evaluate its responses using MLflow Evaluation\n",
    "- Log the agent with MLflow and deploy it to a model serving endpoint\n",
    "\n",
    "This notebook uses the  [`ResponsesAgent`](https://mlflow.org/docs/latest/api_reference/python_api/mlflow.pyfunc.html#mlflow.pyfunc.ResponsesAgent) for Databrick compatibility.\n",
    "\n",
    "To learn more about authoring an agent using Mosaic AI Agent Framework, see Databricks documentation ([AWS](https://docs.databricks.com/aws/generative-ai/agent-framework/author-agent) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/create-chat-model)).\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Address all `TODO`s in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c107c2c4-df71-4402-b82f-82e2f2d64399",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq --force-reinstall databricks-langchain databricks-agents uv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c715704-ad67-45c9-a870-65728a01f38e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "18db682c-b2a3-48b0-9e91-b2b811419531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define the agent code\n",
    "\n",
    "Define the agent code in a single cell below. This lets you easily write the agent\n",
    "code to a local Python file, using the `%%writefile` magic command, for subsequent\n",
    "logging and deployment.\n",
    "\n",
    "**What this code does at a high level:**\n",
    "\n",
    "1. **Connect to MCP servers using adapters**\n",
    "    The `DatabricksMCPServer` and `DatabricksMultiServerMCPClient` from `databricks_langchain` handle:\n",
    "    - Connections to Databricks MCP servers\n",
    "    - Authentication\n",
    "    - Automatic tool discovery and conversion to LangChain-compatible format\n",
    "\n",
    "2. **Build a LangGraph agent workflow using LangGraph `StateGraph`**\n",
    "\n",
    "3. **Handle streaming responses**\n",
    "    The `MCPToolCallingAgent` class wraps the LangGraph workflow to:\n",
    "    - Process streaming events from the agent graph in real-time\n",
    "    - Convert LangChain message formats to Mosaic AI-compatible format\n",
    "    - Enable MLflow tracing for each step of the agent workflow\n",
    "\n",
    "4. **Wrap with ResponsesAgent**\n",
    "    The agent is wrapped using `ResponsesAgent` for compatibility with Databricks\n",
    "    features like evaluation, deployment, and feedback collection.\n",
    "\n",
    "5. **MLflow autotracing**\n",
    "    Enable MLflow autologging to automatically trace LLM calls, tool invocations,\n",
    "    and agent state transitions.\n",
    "\n",
    "#### Agent tools\n",
    "\n",
    "This example connects to the Unity Catalog functions MCP server to access\n",
    "`system.ai.python_exec` (a built-in Python code interpreter). The code also\n",
    "includes commented-out examples for connecting to:\n",
    "- Custom MCP servers (hosted as Databricks Apps)\n",
    "- Vector search MCP servers (for semantic search over your data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a440f1ad-f51c-4f69-a081-94d8b2fa722d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "\n",
    "import asyncio\n",
    "from typing import Annotated, Any, AsyncGenerator, Generator, Optional, Sequence, TypedDict, Union\n",
    "\n",
    "import mlflow\n",
    "import nest_asyncio\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks_langchain import (\n",
    "    ChatDatabricks,\n",
    "    DatabricksMCPServer,\n",
    "    DatabricksMultiServerMCPClient,\n",
    ")\n",
    "from langchain.messages import AIMessage, AIMessageChunk, AnyMessage\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    "    output_to_responses_items_stream,\n",
    "    to_chat_completions_input,\n",
    ")\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "import json\n",
    "\n",
    "nest_asyncio.apply()\n",
    "############################################\n",
    "## Define your LLM endpoint and system prompt\n",
    "############################################\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "# TODO: Update with your system prompt\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that can run Python code.\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Choose your MCP server connection type and setup the Workspace Clients for Authentication\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Managed MCP Server — simplest setup\n",
    "# ---------------------------------------------------------------------------\n",
    "# Databricks manages this connection automatically using your workspace settings\n",
    "# and Personal Access Token (PAT) authentication.\n",
    "\n",
    "workspace_client = WorkspaceClient()\n",
    "\n",
    "host = workspace_client.config.host\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Custom MCP Server — hosted as a Databricks App\n",
    "# ---------------------------------------------------------------------------\n",
    "# Use this if you’re running your own MCP server in Databricks.\n",
    "# These require OAuth with a service principal for machine-to-machine (M2M) auth.\n",
    "#\n",
    "# Follow the insturctions here in order to create a SP, grant the SP query permissions on your app and then mint a client id and # secret. https://docs.databricks.com/aws/en/dev-tools/auth/oauth-m2m\n",
    "#\n",
    "# Uncomment and fill in the settings below to use a custom MCP server.\n",
    "#\n",
    "# import os\n",
    "# custom_mcp_server_workspace_client = WorkspaceClient(\n",
    "#     host=\"<DATABRICKS_WORKSPACE_URL>\",\n",
    "#     client_id=os.getenv(\"DATABRICKS_CLIENT_ID\"),\n",
    "#     client_secret=os.getenv(\"DATABRICKS_CLIENT_SECRET\"),\n",
    "#     auth_type=\"oauth-m2m\",  # Enables service principal authentication\n",
    "# )\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# OBO Setup\n",
    "# ---------------------------------------------------------------------------\n",
    "# In order to use OBO, uncomment the code below and pass this workspace client to the appropriate McpServer below\n",
    "#\n",
    "# from databricks_ai_bridge import ModelServingUserCredentials\n",
    "# obo_workspace_client = WorkspaceClient(credentials_strategy=ModelServingUserCredentials())\n",
    "\n",
    "###############################################################################\n",
    "## Configure MCP Servers for your agent\n",
    "##\n",
    "## This section sets up server connections so your agent can retrieve data or take actions.\n",
    "\n",
    "## There are three connection types:\n",
    "## 1. Managed MCP servers — fully managed by Databricks\n",
    "## 2. External MCP servers — hosted outside Databricks but proxied through a\n",
    "##    Managed MCP server proxy\n",
    "## 3. Custom MCP servers — MCP servers hosted as Databricks Apps\n",
    "##\n",
    "###############################################################################\n",
    "databricks_mcp_client = DatabricksMultiServerMCPClient(\n",
    "    [\n",
    "        DatabricksMCPServer(\n",
    "            name=\"system-ai\",\n",
    "            url=f\"{host}/api/2.0/mcp/functions/system/ai\",\n",
    "        ),\n",
    "        # DatabricksMCPServer(\n",
    "        #     name=\"custom_mcp\",\n",
    "        #     url=\"custom_app_url\",\n",
    "        #     workspace_client=custom_mcp_server_workspace_client\n",
    "        # ),\n",
    "        # DatabricksMCPServer(\n",
    "        #     name=\"obo_vs_client\",\n",
    "        #     url=f\"{host}/api/2.0/mcp/vector-search/system/ai\",\n",
    "        #     workspace_client=obo_workspace_client\n",
    "        # )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# The state for the agent workflow, including the conversation and any custom data\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[AnyMessage], add_messages]\n",
    "    custom_inputs: Optional[dict[str, Any]]\n",
    "    custom_outputs: Optional[dict[str, Any]]\n",
    "\n",
    "\n",
    "def create_tool_calling_agent(\n",
    "    model: LanguageModelLike,\n",
    "    tools: Union[ToolNode, Sequence[BaseTool]],\n",
    "    system_prompt: Optional[str] = None,\n",
    "):\n",
    "    model = model.bind_tools(tools)  # Bind tools to the model\n",
    "\n",
    "    # Function to check if agent should continue or finish based on last message\n",
    "    def should_continue(state: AgentState):\n",
    "        messages = state[\"messages\"]\n",
    "        last_message = messages[-1]\n",
    "        # If function (tool) calls are present, continue; otherwise, end\n",
    "        if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "            return \"continue\"\n",
    "        else:\n",
    "            return \"end\"\n",
    "\n",
    "    # Preprocess: optionally prepend a system prompt to the conversation history\n",
    "    if system_prompt:\n",
    "        preprocessor = RunnableLambda(\n",
    "            lambda state: [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "        )\n",
    "    else:\n",
    "        preprocessor = RunnableLambda(lambda state: state[\"messages\"])\n",
    "\n",
    "    model_runnable = preprocessor | model  # Chain the preprocessor and the model\n",
    "\n",
    "    # The function to invoke the model within the workflow\n",
    "    def call_model(\n",
    "        state: AgentState,\n",
    "        config: RunnableConfig,\n",
    "    ):\n",
    "        response = model_runnable.invoke(state, config)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    workflow = StateGraph(AgentState)  # Create the agent's state machine\n",
    "\n",
    "    workflow.add_node(\"agent\", RunnableLambda(call_model))  # Agent node (LLM)\n",
    "    workflow.add_node(\"tools\", ToolNode(tools))  # Tools node\n",
    "\n",
    "    workflow.set_entry_point(\"agent\")  # Start at agent node\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\",\n",
    "        should_continue,\n",
    "        {\n",
    "            \"continue\": \"tools\",  # If the model requests a tool call, move to tools node\n",
    "            \"end\": END,  # Otherwise, end the workflow\n",
    "        },\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")  # After tools are called, return to agent node\n",
    "\n",
    "    # Compile and return the tool-calling agent workflow\n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "# ResponsesAgent class to wrap the compiled agent and make it compatible with Mosaic AI Responses API\n",
    "class LangGraphResponsesAgent(ResponsesAgent):\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "\n",
    "    # Make a prediction (single-step) for the agent\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\" or event.type == \"error\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(output=outputs, custom_outputs=request.custom_inputs)\n",
    "\n",
    "    async def _predict_stream_async(\n",
    "        self,\n",
    "        request: ResponsesAgentRequest,\n",
    "    ) -> AsyncGenerator[ResponsesAgentStreamEvent, None]:\n",
    "        cc_msgs = to_chat_completions_input([i.model_dump() for i in request.input])\n",
    "        # Stream events from the agent graph\n",
    "        async for event in self.agent.astream(\n",
    "            {\"messages\": cc_msgs}, stream_mode=[\"updates\", \"messages\"]\n",
    "        ):\n",
    "            if event[0] == \"updates\":\n",
    "                # Stream updated messages from the workflow nodes\n",
    "                for node_data in event[1].values():\n",
    "                    if len(node_data.get(\"messages\", [])) > 0:\n",
    "                        all_messages = []\n",
    "                        for msg in node_data[\"messages\"]:\n",
    "                            if isinstance(msg, ToolMessage) and not isinstance(msg.content, str):\n",
    "                                msg.content = json.dumps(msg.content)\n",
    "                            all_messages.append(msg)\n",
    "                        for item in output_to_responses_items_stream(all_messages):\n",
    "                            yield item\n",
    "            elif event[0] == \"messages\":\n",
    "                # Stream generated text message chunks\n",
    "                try:\n",
    "                    chunk = event[1][0]\n",
    "                    if isinstance(chunk, AIMessageChunk) and (content := chunk.content):\n",
    "                        yield ResponsesAgentStreamEvent(\n",
    "                            **self.create_text_delta(delta=content, item_id=chunk.id),\n",
    "                        )\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    # Stream predictions for the agent, yielding output as it's generated\n",
    "    def predict_stream(\n",
    "        self, request: ResponsesAgentRequest\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        agen = self._predict_stream_async(request)\n",
    "\n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "        except RuntimeError:\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "\n",
    "        ait = agen.__aiter__()\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                item = loop.run_until_complete(ait.__anext__())\n",
    "            except StopAsyncIteration:\n",
    "                break\n",
    "            else:\n",
    "                yield item\n",
    "\n",
    "\n",
    "# Initialize the entire agent, including MCP tools and workflow\n",
    "def initialize_agent():\n",
    "    \"\"\"Initialize the agent with MCP tools\"\"\"\n",
    "    # Create MCP tools from the configured servers\n",
    "    mcp_tools = asyncio.run(databricks_mcp_client.get_tools())\n",
    "\n",
    "    # Create the agent graph with an LLM, tool set, and system prompt (if given)\n",
    "    agent = create_tool_calling_agent(llm, mcp_tools, system_prompt)\n",
    "    return LangGraphResponsesAgent(agent)\n",
    "\n",
    "\n",
    "mlflow.langchain.autolog()\n",
    "AGENT = initialize_agent()\n",
    "mlflow.models.set_model(AGENT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e95c42b9-7cd5-4a76-a5c2-cf6ed7af87e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test the agent\n",
    "\n",
    "Interact with the agent to test its output and tool-calling abilities. Since this notebook called `mlflow.langchain.autolog()`, you can view the trace for each step the agent takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "076c0e67-b4ab-45b0-bb13-5b7952402270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b9394fd-d664-4f5e-9efd-8ff6b4ef3814",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# TODO: ONLY UNCOMMENT AND EDIT THIS SECTION IF YOU ARE USING OAUTH/SERVICE PRINCIPAL FOR CUSTOM MCP SERVERS.\n",
    "#       For managed MCP (the default), LEAVE THIS SECTION COMMENTED OUT.\n",
    "# ==============================================================================\n",
    "\n",
    "# import os\n",
    "\n",
    "# # Set your Databricks client ID and client secret for service principal authentication.\n",
    "# DATABRICKS_CLIENT_ID = \"<YOUR_CLIENT_ID>\"\n",
    "# client_secret_scope_name = \"<YOUR_SECRET_SCOPE>\"\n",
    "# client_secret_key_name = \"<YOUR_SECRET_KEY_NAME>\"\n",
    "\n",
    "# # Load your service principal credentials into environment variables\n",
    "# os.environ[\"DATABRICKS_CLIENT_ID\"] = DATABRICKS_CLIENT_ID\n",
    "# os.environ[\"DATABRICKS_CLIENT_SECRET\"] = dbutils.secrets.get(scope=client_secret_scope_name, key=client_secret_key_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6da1040-45b9-4e8e-9640-e2b64931c1a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT\n",
    "\n",
    "AGENT.predict({\"input\": [{\"role\": \"user\", \"content\": \"What is 7*6 in Python?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10003231-75e0-4f15-b453-34d16e46077e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for chunk in AGENT.predict_stream(\n",
    "    {\"input\": [{\"role\": \"user\", \"content\": \"What is 7*6 in Python?\"}]}\n",
    "):\n",
    "    print(chunk, \"-----------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ce59709-8c40-49f0-8e04-f8307b5ac1cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [Deploy an agent that connects to Databricks MCP servers](https://docs.databricks.com/aws/en/generative-ai/mcp/managed-mcp#deploy-your-agent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34ac82c9-1bda-4e14-a579-c3fba00f0123",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from agent import LLM_ENDPOINT_NAME\n",
    "from mlflow.models.resources import DatabricksServingEndpoint, DatabricksFunction\n",
    "from pkg_resources import get_distribution\n",
    "\n",
    "resources = [\n",
    "    DatabricksServingEndpoint(endpoint_name=LLM_ENDPOINT_NAME), \n",
    "    DatabricksFunction(function_name=\"system.ai.python_exec\")\n",
    "]\n",
    "\n",
    "with mlflow.start_run():\n",
    "    logged_agent_info = mlflow.pyfunc.log_model(\n",
    "        name=\"agent\",\n",
    "        python_model=\"agent.py\",\n",
    "        resources=resources,\n",
    "        pip_requirements=[\n",
    "            f\"langgraph=={get_distribution('langgraph').version}\",\n",
    "            f\"mcp=={get_distribution('mcp').version}\",\n",
    "            f\"databricks-mcp=={get_distribution('databricks-mcp').version}\",\n",
    "            f\"databricks-langchain=={get_distribution('databricks-langchain').version}\",\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acdd669d-7ade-4ff1-a5d8-1f540948d57a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Evaluate the agent with [Agent Evaluation](https://docs.databricks.com/mlflow3/genai/eval-monitor)\n",
    "\n",
    "You can edit the requests or expected responses in your evaluation dataset and run evaluation as you iterate your agent, leveraging mlflow to track the computed quality metrics.\n",
    "\n",
    "Evaluate your agent with one of our [predefined LLM scorers](https://docs.databricks.com/mlflow3/genai/eval-monitor/predefined-judge-scorers), or try adding [custom metrics](https://docs.databricks.com/mlflow3/genai/eval-monitor/custom-scorers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0266ee29-1fc8-41cc-84c0-63ffcef9f392",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.genai.scorers import RelevanceToQuery, Safety, RetrievalRelevance, RetrievalGroundedness\n",
    "\n",
    "eval_dataset = [\n",
    "    {\n",
    "        \"inputs\": {\n",
    "            \"input\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": \"Calculate the 15th Fibonacci number\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"expected_response\": \"The 15th Fibonacci number is 610.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "eval_results = mlflow.genai.evaluate(\n",
    "    data=eval_dataset,\n",
    "    predict_fn=lambda input: AGENT.predict({\"input\": input}),\n",
    "    scorers=[RelevanceToQuery(), Safety()], # add more scorers here if they're applicable\n",
    ")\n",
    "\n",
    "# Review the evaluation results in the MLfLow UI (see console output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95ffc536-f9c1-45b0-890c-9b382c9552ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.models.predict(\n",
    "    model_uri=f\"runs:/{logged_agent_info.run_id}/agent\",\n",
    "    input_data={\"input\": [{\"role\": \"user\", \"content\": \"What is 7*6 in Python?\"}]},\n",
    "    env_manager=\"uv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3989e7dd-c714-4ea5-ac33-e50b6b8e22ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the model to Unity Catalog\n",
    "\n",
    "Before you deploy the agent, you must register the agent to Unity Catalog.\n",
    "\n",
    "- **TODO** Update the `catalog`, `schema`, and `model_name` below to register the MLflow model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c22837d-2b8c-4f92-8653-135268632270",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mRestException\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:468\u001B[0m, in \u001B[0;36mUcModelRegistryStore.create_registered_model\u001B[0;34m(self, name, tags, description, deployment_job_id)\u001B[0m\n",
       "\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 468\u001B[0m     response_proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_endpoint(CreateRegisteredModelRequest, req_body)\n",
       "\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RestException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/store/model_registry/base_rest_store.py:42\u001B[0m, in \u001B[0;36mBaseRestStore._call_endpoint\u001B[0;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001B[0m\n",
       "\u001B[1;32m     41\u001B[0m endpoint, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_endpoint_from_method(api)\n",
       "\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_endpoint(\n",
       "\u001B[1;32m     43\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_host_creds(), endpoint, method, json_body, response_proto, extra_headers\n",
       "\u001B[1;32m     44\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:596\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001B[0m\n",
       "\u001B[1;32m    594\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n",
       "\u001B[0;32m--> 596\u001B[0m response \u001B[38;5;241m=\u001B[39m verify_rest_response(response, endpoint)\n",
       "\u001B[1;32m    597\u001B[0m response_to_parse \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mtext\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:315\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[0;34m(response, endpoint)\u001B[0m\n",
       "\u001B[1;32m    314\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n",
       "\u001B[0;32m--> 315\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RestException(json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext))\n",
       "\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\n",
       "\u001B[0;31mRestException\u001B[0m: INVALID_PARAMETER_VALUE: Bad model name: please specify all three levels of the model in the form `catalog_name.schema_name.model_name`\n",
       "\n",
       "During handling of the above exception, another exception occurred:\n",
       "\n",
       "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-8612596643949916>, line 10\u001B[0m\n",
       "\u001B[1;32m      7\u001B[0m UC_MODEL_NAME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcatalog\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mschema\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# register the model to UC\u001B[39;00m\n",
       "\u001B[0;32m---> 10\u001B[0m uc_registered_model_info \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mregister_model(\n",
       "\u001B[1;32m     11\u001B[0m     model_uri\u001B[38;5;241m=\u001B[39mlogged_agent_info\u001B[38;5;241m.\u001B[39mmodel_uri, name\u001B[38;5;241m=\u001B[39mUC_MODEL_NAME\n",
       "\u001B[1;32m     12\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/_model_registry/fluent.py:136\u001B[0m, in \u001B[0;36mregister_model\u001B[0;34m(model_uri, name, await_registration_for, tags, env_pack)\u001B[0m\n",
       "\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mregister_model\u001B[39m(\n",
       "\u001B[1;32m     67\u001B[0m     model_uri,\n",
       "\u001B[1;32m     68\u001B[0m     name,\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     72\u001B[0m     env_pack: EnvPackType \u001B[38;5;241m|\u001B[39m EnvPackConfig \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n",
       "\u001B[1;32m     73\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ModelVersion:\n",
       "\u001B[1;32m     74\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001B[39;00m\n",
       "\u001B[1;32m     75\u001B[0m \n",
       "\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    134\u001B[0m \u001B[38;5;124;03m        Version: 1\u001B[39;00m\n",
       "\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
       "\u001B[0;32m--> 136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _register_model(\n",
       "\u001B[1;32m    137\u001B[0m         model_uri\u001B[38;5;241m=\u001B[39mmodel_uri,\n",
       "\u001B[1;32m    138\u001B[0m         name\u001B[38;5;241m=\u001B[39mname,\n",
       "\u001B[1;32m    139\u001B[0m         await_registration_for\u001B[38;5;241m=\u001B[39mawait_registration_for,\n",
       "\u001B[1;32m    140\u001B[0m         tags\u001B[38;5;241m=\u001B[39mtags,\n",
       "\u001B[1;32m    141\u001B[0m         env_pack\u001B[38;5;241m=\u001B[39menv_pack,\n",
       "\u001B[1;32m    142\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/_model_registry/fluent.py:167\u001B[0m, in \u001B[0;36m_register_model\u001B[0;34m(model_uri, name, await_registration_for, tags, local_model_path, env_pack)\u001B[0m\n",
       "\u001B[1;32m    163\u001B[0m         eprint(\n",
       "\u001B[1;32m    164\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRegistered model \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m already exists. Creating a new version of this model...\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    165\u001B[0m         )\n",
       "\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[0;32m--> 167\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n",
       "\u001B[1;32m    169\u001B[0m run_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\u001B[1;32m    170\u001B[0m model_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/_model_registry/fluent.py:156\u001B[0m, in \u001B[0;36m_register_model\u001B[0;34m(model_uri, name, await_registration_for, tags, local_model_path, env_pack)\u001B[0m\n",
       "\u001B[1;32m    154\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient()\n",
       "\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 156\u001B[0m     create_model_response \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mcreate_registered_model(name)\n",
       "\u001B[1;32m    157\u001B[0m     eprint(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuccessfully registered model \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcreate_model_response\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/client.py:3842\u001B[0m, in \u001B[0;36mMlflowClient.create_registered_model\u001B[0;34m(self, name, tags, description, deployment_job_id)\u001B[0m\n",
       "\u001B[1;32m   3839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_prompt_tag(tags):\n",
       "\u001B[1;32m   3840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException\u001B[38;5;241m.\u001B[39minvalid_parameter_value(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompts cannot be registered as models.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
       "\u001B[0;32m-> 3842\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_registry_client()\u001B[38;5;241m.\u001B[39mcreate_registered_model(\n",
       "\u001B[1;32m   3843\u001B[0m     name, tags, description, deployment_job_id\n",
       "\u001B[1;32m   3844\u001B[0m )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/telemetry/track.py:24\u001B[0m, in \u001B[0;36mrecord_usage_event.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     21\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n",
       "\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m R:\n",
       "\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_telemetry_disabled() \u001B[38;5;129;01mor\u001B[39;00m _is_telemetry_disabled_for_event(event):\n",
       "\u001B[0;32m---> 24\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
       "\u001B[1;32m     26\u001B[0m     success \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
       "\u001B[1;32m     27\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/_model_registry/client.py:96\u001B[0m, in \u001B[0;36mModelRegistryClient.create_registered_model\u001B[0;34m(self, name, tags, description, deployment_job_id)\u001B[0m\n",
       "\u001B[1;32m     94\u001B[0m tags \u001B[38;5;241m=\u001B[39m tags \u001B[38;5;129;01mor\u001B[39;00m {}\n",
       "\u001B[1;32m     95\u001B[0m tags \u001B[38;5;241m=\u001B[39m [RegisteredModelTag(key, \u001B[38;5;28mstr\u001B[39m(value)) \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m tags\u001B[38;5;241m.\u001B[39mitems()]\n",
       "\u001B[0;32m---> 96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore\u001B[38;5;241m.\u001B[39mcreate_registered_model(name, tags, description, deployment_job_id)\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:489\u001B[0m, in \u001B[0;36mUcModelRegistryStore.create_registered_model\u001B[0;34m(self, name, tags, description, deployment_job_id)\u001B[0m\n",
       "\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecify all three levels\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m e\u001B[38;5;241m.\u001B[39mmessage:\n",
       "\u001B[1;32m    479\u001B[0m     \u001B[38;5;66;03m# The exception is likely due to the user trying to create a registered model\u001B[39;00m\n",
       "\u001B[1;32m    480\u001B[0m     \u001B[38;5;66;03m# in Unity Catalog without specifying a 3-level name (catalog.schema.model).\u001B[39;00m\n",
       "\u001B[1;32m    481\u001B[0m     \u001B[38;5;66;03m# The user may not be intending to use the Unity Catalog Model Registry at all,\u001B[39;00m\n",
       "\u001B[1;32m    482\u001B[0m     \u001B[38;5;66;03m# but rather the legacy Workspace Model Registry. Accordingly, we re-raise with\u001B[39;00m\n",
       "\u001B[1;32m    483\u001B[0m     \u001B[38;5;66;03m# a hint\u001B[39;00m\n",
       "\u001B[1;32m    484\u001B[0m     legacy_hint \u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[1;32m    485\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf you are trying to use the legacy Workspace Model Registry, instead of the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    486\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m recommended Unity Catalog Model Registry, set the Model Registry URI to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    487\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatabricks\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (legacy) instead of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatabricks-uc\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (recommended).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    488\u001B[0m     )\n",
       "\u001B[0;32m--> 489\u001B[0m     reraise_with_legacy_hint(exception\u001B[38;5;241m=\u001B[39me, legacy_hint\u001B[38;5;241m=\u001B[39mlegacy_hint)\n",
       "\u001B[1;32m    490\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMETASTORE_DOES_NOT_EXIST\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m e\u001B[38;5;241m.\u001B[39mmessage:\n",
       "\u001B[1;32m    491\u001B[0m     legacy_hint \u001B[38;5;241m=\u001B[39m (\n",
       "\u001B[1;32m    492\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf you are trying to use the Model Registry in a Databricks workspace that\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    493\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m does not have Unity Catalog enabled, either enable Unity Catalog in the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    494\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m workspace (recommended) or set the Model Registry URI to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatabricks\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    495\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m use the legacy Workspace Model Registry.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[1;32m    496\u001B[0m     )\n",
       "\n",
       "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:473\u001B[0m, in \u001B[0;36mUcModelRegistryStore.create_registered_model.<locals>.reraise_with_legacy_hint\u001B[0;34m(exception, legacy_hint)\u001B[0m\n",
       "\u001B[1;32m    471\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreraise_with_legacy_hint\u001B[39m(exception, legacy_hint):\n",
       "\u001B[1;32m    472\u001B[0m     new_message \u001B[38;5;241m=\u001B[39m exception\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mrstrip(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlegacy_hint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
       "\u001B[0;32m--> 473\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n",
       "\u001B[1;32m    474\u001B[0m         message\u001B[38;5;241m=\u001B[39mnew_message,\n",
       "\u001B[1;32m    475\u001B[0m         error_code\u001B[38;5;241m=\u001B[39mexception\u001B[38;5;241m.\u001B[39merror_code,\n",
       "\u001B[1;32m    476\u001B[0m     )\n",
       "\n",
       "\u001B[0;31mMlflowException\u001B[0m: INVALID_PARAMETER_VALUE: Bad model name: please specify all three levels of the model in the form `catalog_name.schema_name.model_name`. If you are trying to use the legacy Workspace Model Registry, instead of the recommended Unity Catalog Model Registry, set the Model Registry URI to 'databricks' (legacy) instead of 'databricks-uc' (recommended)."
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "MlflowException",
        "evalue": "INVALID_PARAMETER_VALUE: Bad model name: please specify all three levels of the model in the form `catalog_name.schema_name.model_name`. If you are trying to use the legacy Workspace Model Registry, instead of the recommended Unity Catalog Model Registry, set the Model Registry URI to 'databricks' (legacy) instead of 'databricks-uc' (recommended)."
       },
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": {
        "breakingChangeInfo": null,
        "errorClass": "USER_SESSION_SCOPE_DATABRICKS_LIBRARY_ERROR",
        "pysparkCallSite": null,
        "pysparkFragment": null,
        "pysparkSummary": null,
        "sqlState": "KAN01",
        "stackTrace": null,
        "startIndex": null,
        "stopIndex": null
       },
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mRestException\u001B[0m                             Traceback (most recent call last)",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:468\u001B[0m, in \u001B[0;36mUcModelRegistryStore.create_registered_model\u001B[0;34m(self, name, tags, description, deployment_job_id)\u001B[0m\n\u001B[1;32m    467\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 468\u001B[0m     response_proto \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_endpoint(CreateRegisteredModelRequest, req_body)\n\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m RestException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/store/model_registry/base_rest_store.py:42\u001B[0m, in \u001B[0;36mBaseRestStore._call_endpoint\u001B[0;34m(self, api, json_body, call_all_endpoints, extra_headers)\u001B[0m\n\u001B[1;32m     41\u001B[0m endpoint, method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_endpoint_from_method(api)\n\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m call_endpoint(\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_host_creds(), endpoint, method, json_body, response_proto, extra_headers\n\u001B[1;32m     44\u001B[0m )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:596\u001B[0m, in \u001B[0;36mcall_endpoint\u001B[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001B[0m\n\u001B[1;32m    594\u001B[0m     response \u001B[38;5;241m=\u001B[39m http_request(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcall_kwargs)\n\u001B[0;32m--> 596\u001B[0m response \u001B[38;5;241m=\u001B[39m verify_rest_response(response, endpoint)\n\u001B[1;32m    597\u001B[0m response_to_parse \u001B[38;5;241m=\u001B[39m response\u001B[38;5;241m.\u001B[39mtext\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/utils/rest_utils.py:315\u001B[0m, in \u001B[0;36mverify_rest_response\u001B[0;34m(response, endpoint)\u001B[0m\n\u001B[1;32m    314\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _can_parse_as_json_object(response\u001B[38;5;241m.\u001B[39mtext):\n\u001B[0;32m--> 315\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RestException(json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mtext))\n\u001B[1;32m    316\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
        "\u001B[0;31mRestException\u001B[0m: INVALID_PARAMETER_VALUE: Bad model name: please specify all three levels of the model in the form `catalog_name.schema_name.model_name`",
        "\nDuring handling of the above exception, another exception occurred:\n",
        "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
        "File \u001B[0;32m<command-8612596643949916>, line 10\u001B[0m\n\u001B[1;32m      7\u001B[0m UC_MODEL_NAME \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcatalog\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mschema\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# register the model to UC\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m uc_registered_model_info \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mregister_model(\n\u001B[1;32m     11\u001B[0m     model_uri\u001B[38;5;241m=\u001B[39mlogged_agent_info\u001B[38;5;241m.\u001B[39mmodel_uri, name\u001B[38;5;241m=\u001B[39mUC_MODEL_NAME\n\u001B[1;32m     12\u001B[0m )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/_model_registry/fluent.py:136\u001B[0m, in \u001B[0;36mregister_model\u001B[0;34m(model_uri, name, await_registration_for, tags, env_pack)\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mregister_model\u001B[39m(\n\u001B[1;32m     67\u001B[0m     model_uri,\n\u001B[1;32m     68\u001B[0m     name,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     72\u001B[0m     env_pack: EnvPackType \u001B[38;5;241m|\u001B[39m EnvPackConfig \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     73\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ModelVersion:\n\u001B[1;32m     74\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Create a new model version in model registry for the model files specified by ``model_uri``.\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \n\u001B[1;32m     76\u001B[0m \u001B[38;5;124;03m    Note that this method assumes the model registry backend URI is the same as that of the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;124;03m        Version: 1\u001B[39;00m\n\u001B[1;32m    135\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _register_model(\n\u001B[1;32m    137\u001B[0m         model_uri\u001B[38;5;241m=\u001B[39mmodel_uri,\n\u001B[1;32m    138\u001B[0m         name\u001B[38;5;241m=\u001B[39mname,\n\u001B[1;32m    139\u001B[0m         await_registration_for\u001B[38;5;241m=\u001B[39mawait_registration_for,\n\u001B[1;32m    140\u001B[0m         tags\u001B[38;5;241m=\u001B[39mtags,\n\u001B[1;32m    141\u001B[0m         env_pack\u001B[38;5;241m=\u001B[39menv_pack,\n\u001B[1;32m    142\u001B[0m     )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/_model_registry/fluent.py:167\u001B[0m, in \u001B[0;36m_register_model\u001B[0;34m(model_uri, name, await_registration_for, tags, local_model_path, env_pack)\u001B[0m\n\u001B[1;32m    163\u001B[0m         eprint(\n\u001B[1;32m    164\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRegistered model \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m!r}\u001B[39;00m\u001B[38;5;124m already exists. Creating a new version of this model...\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    165\u001B[0m         )\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 167\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    169\u001B[0m run_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    170\u001B[0m model_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/_model_registry/fluent.py:156\u001B[0m, in \u001B[0;36m_register_model\u001B[0;34m(model_uri, name, await_registration_for, tags, local_model_path, env_pack)\u001B[0m\n\u001B[1;32m    154\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient()\n\u001B[1;32m    155\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 156\u001B[0m     create_model_response \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mcreate_registered_model(name)\n\u001B[1;32m    157\u001B[0m     eprint(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSuccessfully registered model \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcreate_model_response\u001B[38;5;241m.\u001B[39mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    158\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MlflowException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/client.py:3842\u001B[0m, in \u001B[0;36mMlflowClient.create_registered_model\u001B[0;34m(self, name, tags, description, deployment_job_id)\u001B[0m\n\u001B[1;32m   3839\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_prompt_tag(tags):\n\u001B[1;32m   3840\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException\u001B[38;5;241m.\u001B[39minvalid_parameter_value(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPrompts cannot be registered as models.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 3842\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_registry_client()\u001B[38;5;241m.\u001B[39mcreate_registered_model(\n\u001B[1;32m   3843\u001B[0m     name, tags, description, deployment_job_id\n\u001B[1;32m   3844\u001B[0m )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/telemetry/track.py:24\u001B[0m, in \u001B[0;36mrecord_usage_event.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs: P\u001B[38;5;241m.\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: P\u001B[38;5;241m.\u001B[39mkwargs) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m R:\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_telemetry_disabled() \u001B[38;5;129;01mor\u001B[39;00m _is_telemetry_disabled_for_event(event):\n\u001B[0;32m---> 24\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     26\u001B[0m     success \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     27\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/tracking/_model_registry/client.py:96\u001B[0m, in \u001B[0;36mModelRegistryClient.create_registered_model\u001B[0;34m(self, name, tags, description, deployment_job_id)\u001B[0m\n\u001B[1;32m     94\u001B[0m tags \u001B[38;5;241m=\u001B[39m tags \u001B[38;5;129;01mor\u001B[39;00m {}\n\u001B[1;32m     95\u001B[0m tags \u001B[38;5;241m=\u001B[39m [RegisteredModelTag(key, \u001B[38;5;28mstr\u001B[39m(value)) \u001B[38;5;28;01mfor\u001B[39;00m key, value \u001B[38;5;129;01min\u001B[39;00m tags\u001B[38;5;241m.\u001B[39mitems()]\n\u001B[0;32m---> 96\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstore\u001B[38;5;241m.\u001B[39mcreate_registered_model(name, tags, description, deployment_job_id)\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:489\u001B[0m, in \u001B[0;36mUcModelRegistryStore.create_registered_model\u001B[0;34m(self, name, tags, description, deployment_job_id)\u001B[0m\n\u001B[1;32m    478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mspecify all three levels\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m e\u001B[38;5;241m.\u001B[39mmessage:\n\u001B[1;32m    479\u001B[0m     \u001B[38;5;66;03m# The exception is likely due to the user trying to create a registered model\u001B[39;00m\n\u001B[1;32m    480\u001B[0m     \u001B[38;5;66;03m# in Unity Catalog without specifying a 3-level name (catalog.schema.model).\u001B[39;00m\n\u001B[1;32m    481\u001B[0m     \u001B[38;5;66;03m# The user may not be intending to use the Unity Catalog Model Registry at all,\u001B[39;00m\n\u001B[1;32m    482\u001B[0m     \u001B[38;5;66;03m# but rather the legacy Workspace Model Registry. Accordingly, we re-raise with\u001B[39;00m\n\u001B[1;32m    483\u001B[0m     \u001B[38;5;66;03m# a hint\u001B[39;00m\n\u001B[1;32m    484\u001B[0m     legacy_hint \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    485\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf you are trying to use the legacy Workspace Model Registry, instead of the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    486\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m recommended Unity Catalog Model Registry, set the Model Registry URI to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    487\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatabricks\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (legacy) instead of \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatabricks-uc\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (recommended).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    488\u001B[0m     )\n\u001B[0;32m--> 489\u001B[0m     reraise_with_legacy_hint(exception\u001B[38;5;241m=\u001B[39me, legacy_hint\u001B[38;5;241m=\u001B[39mlegacy_hint)\n\u001B[1;32m    490\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMETASTORE_DOES_NOT_EXIST\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m e\u001B[38;5;241m.\u001B[39mmessage:\n\u001B[1;32m    491\u001B[0m     legacy_hint \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    492\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf you are trying to use the Model Registry in a Databricks workspace that\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    493\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m does not have Unity Catalog enabled, either enable Unity Catalog in the\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    494\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m workspace (recommended) or set the Model Registry URI to \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdatabricks\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    495\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m use the legacy Workspace Model Registry.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    496\u001B[0m     )\n",
        "File \u001B[0;32m/local_disk0/.ephemeral_nfs/envs/pythonEnv-df41c661-c45c-48cf-b561-413b3deb7212/lib/python3.12/site-packages/mlflow/store/_unity_catalog/registry/rest_store.py:473\u001B[0m, in \u001B[0;36mUcModelRegistryStore.create_registered_model.<locals>.reraise_with_legacy_hint\u001B[0;34m(exception, legacy_hint)\u001B[0m\n\u001B[1;32m    471\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mreraise_with_legacy_hint\u001B[39m(exception, legacy_hint):\n\u001B[1;32m    472\u001B[0m     new_message \u001B[38;5;241m=\u001B[39m exception\u001B[38;5;241m.\u001B[39mmessage\u001B[38;5;241m.\u001B[39mrstrip(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlegacy_hint\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 473\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m    474\u001B[0m         message\u001B[38;5;241m=\u001B[39mnew_message,\n\u001B[1;32m    475\u001B[0m         error_code\u001B[38;5;241m=\u001B[39mexception\u001B[38;5;241m.\u001B[39merror_code,\n\u001B[1;32m    476\u001B[0m     )\n",
        "\u001B[0;31mMlflowException\u001B[0m: INVALID_PARAMETER_VALUE: Bad model name: please specify all three levels of the model in the form `catalog_name.schema_name.model_name`. If you are trying to use the legacy Workspace Model Registry, instead of the recommended Unity Catalog Model Registry, set the Model Registry URI to 'databricks' (legacy) instead of 'databricks-uc' (recommended)."
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "# TODO: define the catalog, schema, and model name for your UC model\n",
    "catalog = \"\"\n",
    "schema = \"\"\n",
    "model_name = \"\"\n",
    "UC_MODEL_NAME = f\"{catalog}.{schema}.{model_name}\"\n",
    "\n",
    "# register the model to UC\n",
    "uc_registered_model_info = mlflow.register_model(\n",
    "    model_uri=logged_agent_info.model_uri, name=UC_MODEL_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d23daef3-24d6-4708-a01d-5d42ca861384",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Deploy the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f95f3fb0-c5d3-473e-87c0-c34352fb81e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:440)\n",
       "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:486)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:768)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:512)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:632)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$5(UsageLogging.scala:659)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:80)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:172)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:153)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:80)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:627)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:521)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:80)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:513)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:477)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:80)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:740)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequest$1(Chauffeur.scala:943)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$handleDriverRequests$2(Chauffeur.scala:970)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:632)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$5(UsageLogging.scala:659)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.withAttributionContext(Chauffeur.scala:167)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:172)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:153)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.withAttributionTags(Chauffeur.scala:167)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:627)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:521)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.recordOperationWithResultTags(Chauffeur.scala:167)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:969)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequests(Chauffeur.scala:1020)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:828)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:730)\n",
       "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:726)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:721)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:178)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:204)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:204)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:175)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:165)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:512)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:632)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$5(UsageLogging.scala:659)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:172)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:153)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:627)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:521)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:513)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:477)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.executeWithLogging$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:165)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:997)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:917)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:557)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:522)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:1132)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:68)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:1132)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1094)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1075)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$41(ActivityContextFactory.scala:437)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:68)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:437)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:417)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:111)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
       "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)\n",
       "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)\n",
       "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:111)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:93)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.base/java.lang.Thread.run(Thread.java:840)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": ""
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:440)",
        "\tat com.databricks.spark.chauffeur.ExecutionContextManagerV1.cancelExecution(ExecutionContextManagerV1.scala:486)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:768)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:512)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:632)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$5(UsageLogging.scala:659)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:80)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:172)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:153)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:80)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:627)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:521)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:80)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:513)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:477)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:80)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:740)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequest$1(Chauffeur.scala:943)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.$anonfun$handleDriverRequests$2(Chauffeur.scala:970)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:632)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$5(UsageLogging.scala:659)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.withAttributionContext(Chauffeur.scala:167)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:172)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:153)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.withAttributionTags(Chauffeur.scala:167)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:627)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:521)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.recordOperationWithResultTags(Chauffeur.scala:167)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:969)",
        "\tat com.databricks.spark.chauffeur.Chauffeur.handleDriverRequests(Chauffeur.scala:1020)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:828)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$com$databricks$spark$chauffeur$Chauffeur$$nestedInanon$$receiveInternal$1.applyOrElse(Chauffeur.scala:730)",
        "\tat scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:726)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:721)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:178)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:204)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:204)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:175)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:165)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:512)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:632)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$5(UsageLogging.scala:659)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:172)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:153)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:627)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:521)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:513)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:477)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.executeWithLogging$1(ServerBackend.scala:147)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:165)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:997)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:917)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5(JettyServer.scala:557)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$5$adapted(JettyServer.scala:522)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$12(ActivityContextFactory.scala:1132)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:68)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$2(ActivityContextFactory.scala:1132)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:73)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1094)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:1075)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withServiceRequestActivity$41(ActivityContextFactory.scala:437)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:68)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:437)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:522)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:417)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$2(InstrumentedQueuedThreadPool.scala:111)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)",
        "\tat com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:117)",
        "\tat com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:348)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:344)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:115)",
        "\tat com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:112)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:46)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:111)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:132)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:129)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:46)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:93)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.base/java.lang.Thread.run(Thread.java:840)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from databricks import agents\n",
    "\n",
    "agents.deploy(\n",
    "    UC_MODEL_NAME, \n",
    "    uc_registered_model_info.version,\n",
    "    # ==============================================================================\n",
    "    # TODO: ONLY UNCOMMENT AND CONFIGURE THE ENVIRONMENT_VARS SECTION BELOW\n",
    "    #       IF YOU ARE USING OAUTH/SERVICE PRINCIPAL FOR CUSTOM MCP SERVERS.\n",
    "    #       For managed MCP (the default), LEAVE THIS SECTION COMMENTED OUT.\n",
    "    # ==============================================================================\n",
    "    # environment_vars={\n",
    "    #     \"DATABRICKS_CLIENT_ID\": DATABRICKS_CLIENT_ID,\n",
    "    #     \"DATABRICKS_CLIENT_SECRET\": f\"{{{{secrets/{client_secret_scope_name}/{client_secret_key_name}}}}}\"\n",
    "    # },\n",
    "    tags = {\"endpointSource\": \"docs\"},\n",
    "    deploy_feedback_model=False\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "langgraph-mcp-tool-calling-agent",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}